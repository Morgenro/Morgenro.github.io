---
title: 模型提取攻击摸索
date: 2026-01-07 20:54:31
tags: [AI安全, 模型窃取, 深度学习]
description: "系统性探索模型提取攻击（MEA）在不同反馈机制下的实现路径及防御对抗。"
---


## 

   本文记录了我针对“模型提取攻击（Model Extraction Attacks, MEAs）”进行的系统性研究实验。模型窃取本质上是利用黑盒接口的查询-响应机制，通过训练影子模型（Substitute Model）来复制靶机模型（Victim Model）的决策逻辑

   整个研究从最初的软标签（Soft-label）窃取开始，再到硬标签（Hard-label）环境下的决策边界探测，并计划了解更深层次的防御策略

## 项目简介

在“机器学习即服务”（MLaaS）环境下，攻击者通常只能访问受限的 API 1111。本项目旨在通过异构模型（以 VGG-11 拟合 ResNet-18）验证跨架构提取的稳健性。

   实验主要分为以下阶段：

   Stage 1：软标签提取。 利用 API 返回的完整置信度向量，通过分布对齐实现快速克隆。

   Stage 2：硬标签窃取。 在仅能获取类别索引的极端信息受限环境下，通过底层采样策略（二分搜索与邻域增强）探测高维决策边界。

   Stage 3（undo）：防御干扰对抗。 模拟靶机部署差分隐私（DP）、输出扰动及查询检测等防御后的自适应攻击 。

## 文献综述与攻防体系划分

根据 2025 年最新的系统性综述，模型提取攻防已形成严密的分类矩阵 ：

### 攻击 
#### 攻击方法
- **替代模型训练 (Substitute Model Training)：** 利用查询反馈训练功能等价的影子模型（本项目核心逻辑）。
- **方程求解与参数还原：** 针对简单模型或特定激活函数（如 ReLU）进行权重窃取 。
- **解释引导与梯度估计：** 利用热力图或样本梯度加速窃取（如 SPSG 策略）。
#### 攻击数据选择

- **问题域攻击 (Problem Domain)：** 使用与靶机同分布的数据（如本项目对 CIFAR-10 的划分）。
- **非问题域攻击 (Non-problem Domain)：** 利用无关数据通过领域自适应完成提取（如 **Marich** 策略）。
- **无数据攻击 (Data-free)：** 完全依赖 GAN 生成查询样本。

### 防御

- **攻击预防 (Prevention)：** 包含 **对抗训练**（增强鲁棒性）、**输出/数据扰动**（如加入 $\epsilon$-DP 噪声）、**访问控制**（基于速率限制或 PoW）。
- **监测与验证 (Detection & Verification)：**
  - **查询模式监控：** 如 **PRADA** 监测查询分布的统计偏差 。
  - **所有权水印 (Watermarking)：** 在模型中嵌入特定 trigger 以便后事追溯所有权。
  - **指纹识别 (Fingerprinting)：** 利用边界特征生成唯一模型标识。

## 环境配置

Python

```
torch==2.5.1
torchvision==0.20.1
numpy==2.2.6
scipy==1.15.3
scikit-learn==1.7.2
pillow==12.1.0
scikit-image==0.25.2
tqdm==4.67.1
matplotlib==3.10.8
```

## 核心攻击实现方案

### 靶机与 API 环境构建 (Stage 0 - Done)

   靶机采用 ResNet-18 架构，在 CIFAR-10 数据集上训练 50 个 Epoch，达到 **92.63%** 的测试准确率。

### Stage 1: 软标签分布拟合 (Done)

此阶段假设 API 返回完整的 Softmax 概率。通过 KL 散度（Kullback-Leibler Divergence）最小化影子模型与靶机的输出分布差异 14。

   实验数据： 仅 10 轮迭代即达到 67.74% 准确率，保真度（Fidelity）为 81.05%。

### Stage 2: 硬标签边界探测 (Doing)

   这一阶段是本研究的重难点。我们将其分为 **特征空间采样（底层逻辑）** 与 **高阶算法优化（执行方案）**。

#### A. 底层空间采样逻辑

- A1：决策边界二分搜索 (Binary Search) (Done)

     在两类样本间通过线性插值迭代逼近决策边界点。

     结果： 准确率 71.87%，但保真度仅 79.14%，且因查询开销过大耗时达 5 小时。

- A2：邻域采样增强与 Mixup (Done)

     利用大规模数据增强和随机插值填补特征岛屿。

     结果： 保真度高达 90.79%，Mixup 更是将准确率推至 76.29%。

#### B. 主动学习优化 - 变分采样 (Undo)

参考 **Marich** 算法 15，计划通过熵采样（Entropy Sampling）与梯度多样性筛选，只查询对影子模型最具“启发性”的样本，以在有限配额内最大化信息增益 。

#### C. 解释性引导 - 梯度估计 (Undo)

参考 **SPSG** 策略，计划引入超像素扰动（SPGQ）在硬标签下估算伪梯度方向，使影子模型精准学习靶机的决策焦点。

------

## 防御干扰下的攻击 (Stage 3 - Undo)

1. **应对差分隐私与输出扰动：** 研究影子模型在靶机加入 $\epsilon$-DP 噪声干扰下的收敛能力，探索标签细化（Label Refining）过滤技术 。
2. **规避查询模式检测：** 开发伪装采样技术，使攻击查询序列在统计特征上接近合法用户，从而绕过类似 **PRADA** 的拦截 。
3. **对抗主动防御（Honeypots）：** 研究影子模型如何识别并剥离由靶机主动诱导生成的防御性“错误模式” 。

------

## 阶段性实验数据总结 (Evaluation)

| **攻击策略**            | **状态** | **准确率 (Acc)** | **保真度 (Fidelity)** | **核心洞察**                               |
| ----------------------- | -------- | ---------------- | --------------------- | ------------------------------------------ |
| **Stage 1 (Soft)**      | **Done** | 67.74%           | 81.05%                | 信息丰度高，学习最稳健。                   |
| **Stage 2-A1 (Binary)** | **Done** | 71.87%           | 79.14%                | 易陷入分布外“孤岛”，拟合效率低。           |
| **Stage 2-A2 (Aug)**    | **Done** | 72.57%           | **90.79%**            | **最优克隆策略**：大规模采样深度复刻行为。 |
| **Stage 2-Mixup**       | **Done** | **76.29%**       | 86.20%                | 识别力极强，但边界平滑导致克隆度下降。     |

## 总结与思考
